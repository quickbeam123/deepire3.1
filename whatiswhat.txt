General notes:
--------------

Deepire3
- was the third attempt to do clause selection in Vampire using clause derivation features and recursive (tree) neural networks
- previous two were done with Karel, but left (so far) unfinished
- number 3 I hacked alone before AITP2020 in September 2020
- it relies on a branch deepire3 in the Vampire repo
- and uses Pytorch1.6

Deepire3.1 is meant to be polishing of Deepire3
- to serve as a basis of a reasonable publication
- to perform ablations of various kinds, not to rely on intuitions only
- to also support AVATAR, and non-discount saturation algorithms (including LRS)






Python scripts:
---------------

inf_common.py
- routines shared by various scripts below
- "inf" means we are focusing on building a model which only cares about inferences (their id's and id's of input axioms / theory axioms) and nothing else, when deciding good/bad for each clause 
(while the showForKarel part on the vampire sides tries to be more general, i.e., all the other simple features are being output to yield posnegs, the model architecture is, of course, inf-specifif, and, the model reading part in vampire is also inf-specific, which is the annoying part)

- at the beginning, inf_common tries to list all the hyper-parameters, we might care about changing 

- one of them is SWAPOUT, which, when grater than zero, defines the probability (during learning) that a part of the network corresponding to a particular inference or input axiom gets swapped by a generic one; this could work as a regularizer, but also, makes sure the generic gets trained enough so that it can be used for (during learning) unseen inferences (axioms) during vampiric-inference mode

- inf_saver.py is automatically generated by inf_common.py's create_saver function, so that it can have a variable number of methods (which are then reflected in the exported trochscript model and dynamically accessed by vampire)

log_loader.py
- Load a set of logs, passed as arguments, each will become a "training example tree"
- Scan the set and create a histogram (to learn which initial and derivational networks will be needed; including the "dropout" defaults) - save it to "data_hist.pt"
- normalize the training data and save that to "training_data.pt"
- To be called as in: ./log_loader.py data_hist.pt training_data.pt enigma_smt_447/smt4vamp_deepire3_5s_d4858_fastBase0_s4k-on/*.log (an "-s4k on" run of vampire, so far without avatar)

initializer.py
- Load data_hist.pt and create a fresh model save it to "model_name_prefix"+characterization
- To be called as in: ./initializer.py enigma_smt_447/data_hist.pt enigma_smt_447/model0

multi_inf_parallel.py
- the main parallel learning script: slave processes build the graphs and compute gradients, 
the master collects gradients and updates the master model
- the funny bit is that slaves are given jobs as soon as possible,
so the learning is not necessarily equivalent to any serial execution

starter.sh
- an example on how to run multi_inf_parallel.py
- also showing that ulimit must be used to allow more open files per process
(somehow python's pool in combination with what pytorch does opens many many)

loss_plotter.py
- open the file which multi_inf_parallel.py outputs (see also the redirect in start.sh), this is argv[1],
and plot the development of loss into argv[3], only start "recording" when the loss drops below argv[2]

exporter.py
- Load data_hist.pt and trained model; export a torchscript model version of it to argv[3]
- To be called as in: ./exporter.py enigma_smt_447/data_hist.pt enigma_smt_447/models14/inf_14_Tanh_p0.9791753101758176_n0.5020857886700685.pt enigma_smt_447/model_14Tanh_best.pt

data_analyzer.py
- just an auxiliary script I used to have a look at the TPTP's data_hist.pt,
suspecting too simple and too deep derivations (which I was discarding in inf_common's load_one in its last version)

compressor.py
- Some training problems can be grouped together so that they are more evenly sized and parallel graph building pays off.
- Became an integral part of the pipeline. Big compression is not compulsory, but compressing for the abstraction makes sense anyway
(and we no longer learn from good/selec data directly anyway!)

blob_trajectory.py
- For every clause in big_blob.pt (create by compressor), plot it's logits as they develop along training epochs.

calibrator.py
- since multi_inf_parallel(files) no longer evaluates on the whole train/valid set per epoch (it only works with TRAIN_SAMPLES_PER_EPOCH/VALID_SAMPLES_PER_EPOCH), moreover, since the stats from training are anyway not precise (the model keeps changing), in order to pick the best model train/valid/both-wise, does not matter, we will need to use this tool to do the precise eval
- idea: use all the models you are interested in evaluating in-one-go to evaluate on a single merged graph and then on the next (or do this in parallel using workers)

model_visualizer_(raw).py
- load the (raw) dataset and a model
- start looking at individual abstract clauses to see what the models says about them (and perhaps also compare this to the gold thingie...)

model_debugged_(pieces).py
- plots this graph showing the distribution of logits of an obtained model;
in partucular, it attempts to highlihgt the "mass" of positive pieces left "below" the treshold
and the "mass" of the negative ones left above

multi_inf_parallel_files_continuous.py
- since we now have calibrator, let's not stop to validate the checkpoints, simply keep updating the master_parts and report loss as the sliding average of the last "1000" versions.
- also implement heat-up (linear) and cool-down (hyperbolic) home-made learning rate schedule
- also plot standard deviations

loss_plotter_continuous.py
- loss plotter compatible with the output of the above
- (also, optionally, we want to plot ATP eval stats of some selected models)

stats_plotter.py
- collect ML and ATP stats about a bunch of models (indexed by their epoch, for instance)
- and plot them agains one another

active_pieces.py
- scan the run file generated by multi_inf_parallel_files_continuous.py
and keep track of pieces as they go in and out. What are the active pieces by the time one reaches the end of the file?
(This can be useful if the whole server gets stuck because of not enough memory...)
